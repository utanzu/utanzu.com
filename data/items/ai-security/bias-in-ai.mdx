---
title: 'Bias in AI'
topic: 'Bias, Fairness, and Ethics'
course: 'Introduction to AI Security'
category: 'AI Security'
duration: 1
---

AI models learn from data, but if the data contains bias, the AI will also develop biased behaviors. This can lead to discrimination, unfair decision-making, and ethical concerns. Bias in AI is a serious issue that can impact hiring, credit approval, law enforcement, and healthcare.

#### **Scenario: AI in Hiring Discrimination**

A tech company implements an AI-powered hiring system that ranks job applicants. However, because the historical hiring data is biased against female candidates, the AI favors male applicants. As a result, highly qualified women are systematically ranked lower, reinforcing workplace gender disparities.

This scenario demonstrates **algorithmic bias**, where AI amplifies biases that exist in its training data.

### Types of Bias in AI

| Type of Bias         | Description                                               | Example                                                                                               |
| -------------------- | --------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
| **Data Bias**        | Biases that exist in training datasets.                   | A medical AI trained only on male patient data may misdiagnose female patients.                       |
| **Algorithmic Bias** | Bias introduced by model design or training techniques.   | A facial recognition system that works better for lighter skin tones than darker ones.                |
| **Selection Bias**   | Training data does not represent the entire population.   | A real estate AI trained only on urban housing data fails to predict rural housing prices accurately. |
| **Automation Bias**  | Over-reliance on AI decisions without human intervention. | A judge trusts an AI risk-assessment tool without reviewing the case personally.                      |

### Why is AI Bias a Problem?

- **Legal & Ethical Risks**: AI bias can lead to lawsuits and regulatory penalties.
- **Loss of Trust**: Users lose confidence in AI if its decisions are unfair.
- **Negative Social Impact**: AI bias can reinforce discrimination and societal inequities.

### Key Takeaways

- AI bias occurs when **training data or algorithms contain hidden prejudices**.
- AI models can **amplify bias**, leading to systematic unfair decision-making.
- Addressing AI bias is crucial to ensuring **fair, transparent, and ethical AI systems**.

### Further Reading

- [Googleâ€™s AI Fairness Guidelines](https://ai.google/research/)
- [NIST AI Bias Risk Framework](https://www.nist.gov/)
